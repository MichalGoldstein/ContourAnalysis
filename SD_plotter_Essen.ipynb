{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normalise and Plot Melodies, and Save Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "import mir_eval.sonify\n",
    "from mir_eval.sonify import pitch_contour\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitch Estimation and normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_and_normalise(audio, plot = True, sonify = True):\n",
    "    \"\"\" Estimate pitch of an audio input and returns the normalised frequency and time axes\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    audio: np.array\n",
    "        A loaded audio wav file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    f0 : np.array\n",
    "        1D array of estimated frequencies, normalised between 0 and 1\n",
    "    times : np.array\n",
    "        1D time array, normalised between 0 and 1\n",
    "    \n",
    "    \"\"\"\n",
    "    # estimate frequency and time array from the audio input\n",
    "    f0, _, _ = librosa.pyin(audio, fmin=librosa.note_to_hz('C3'), fmax=librosa.note_to_hz('C7'), fill_na = 0)\n",
    "\n",
    "    # replace very large jumps (likely estimation error) with the last frequency value\n",
    "    df = pd.DataFrame(f0) # transform array to dataframe\n",
    "    df_temp = df.mask(df.sub(df.mean()).div(df.std()).abs().gt(2)) # replace outlier values with Nans\n",
    "    df_temp = df_temp.replace(np.nan,0) # replace Nans with zeros\n",
    "    f0 = df_temp.to_numpy() # transform back to numpy array\n",
    "                \n",
    "    # replace zeros (originally Nans) with the last non-zero value\n",
    "    while True:\n",
    "        I=np.nonzero(f0==0)[0]\n",
    "        if len(I)==0: break\n",
    "        f0[I] = f0[I-1]\n",
    "        \n",
    "    # make sure that all phrases are the same length\n",
    "    f0 = f0.reshape(f0.shape[0])\n",
    "    if f0.shape[0] < 431:\n",
    "        num2fill = 431 - f0.shape[0]\n",
    "        f0 = np.pad(f0, (0, num2fill), 'constant')   \n",
    "    if f0.shape[0] > 431:\n",
    "        f0 = f0[:431]\n",
    "    \n",
    "    # create time array\n",
    "#     f0 = f0.reshape(431)\n",
    "    times = librosa.times_like(f0)\n",
    "    \n",
    "    # sonify\n",
    "    if sonify == True:\n",
    "        pc = pitch_contour(times,f0, fs=fs)\n",
    "        a = ipd.Audio(pc,rate=fs)\n",
    "        ipd.display(a)\n",
    "\n",
    "    # normalise frequency and time axes\n",
    "    \n",
    "    normaliser = 1 / np.sum(f0)\n",
    "    f0 *= normaliser\n",
    "    f0 = np.log(f0+1)\n",
    "    \n",
    "#     f0 /= np.max(np.abs(f0),axis=0)\n",
    "#     times /= np.max(np.abs(times),axis=0)\n",
    "\n",
    "#     f0 = (f0 - np.min(f0))/np.ptp(f0)\n",
    "#     times = (times - np.min(times))/np.ptp(times)\n",
    "    \n",
    "\n",
    "    \n",
    "    # plot\n",
    "    if plot==True:\n",
    "        plt.plot(times,f0,'-')\n",
    "        plt.xlabel('time (sec)')\n",
    "        plt.ylabel('frequency (Hz)')\n",
    "        plt.show()\n",
    "        \n",
    "    f0 = f0.reshape(f0.shape[0],1)\n",
    "    \n",
    "    return f0, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset (single-phrases) and store in data matrix\n",
    "(each row is one song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 7.61 %\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m data_set \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(data_set, f0, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m file_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogress:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(file_count\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_dir\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_set = np.empty((431,0), int)\n",
    "\n",
    "file_count = 0\n",
    "audio_dir = 'data/equal_phrases/'\n",
    "for file_name in os.listdir(audio_dir):\n",
    "        if file_name.endswith('.wav'):\n",
    "            # load audio \n",
    "            audio, fs = librosa.load(audio_dir+file_name)\n",
    "            audio,_ = librosa.effects.trim(audio)\n",
    "            # pitch estimation and normalisation\n",
    "            f0, times = estimate_and_normalise(audio, plot = False, sonify = False)\n",
    "            # append pitch contour to data matrix\n",
    "            data_set = np.append(data_set, f0, axis=1)\n",
    "            \n",
    "            file_count += 1\n",
    "            print(\"progress:\", \"{:.2f}\".format(file_count/len(os.listdir(audio_dir))*100), \"%\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_set)\n",
    "plt.xlabel('Relative Time')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.title('Full Data Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset\n",
    "(each row is one song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add file names to dataset\n",
    "data_labels = np.array(glob1(audio_dir,\"*.wav\"))\n",
    "\n",
    "for l in data_labels: # remove .wav\n",
    "    l = l[:-4]\n",
    "\n",
    "country = np.empty((0))\n",
    "seperator = '_'\n",
    "for l in data_labels:\n",
    "    l = l.split(seperator, 1)[0]\n",
    "    country = np.append(country,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data.dat', data_set.T)\n",
    "np.savetxt('country.dat', country.T, delimiter=\" \", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
